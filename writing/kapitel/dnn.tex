\chapter{Einführung Tiefe Neuronal Netze}
\label{chap:dnn}

Die folgenden Abschnitte beschreiben die Funktionsweise von Neuronalen Netzen auf Basis der Erläuterungen in \cite{haykin2007neural}. Neuronale Netze sollen nach \cite{haykin2007neural} in ihrer ursprünglichen Form die neuralen Strukturen des menschlichen Gehirns abbilden. Sie sollen, anders als beispielsweise konventionelle Computer, über die Möglichkeit verfügen, zu lernen. Parallelen zwischen Neuronalen Netzen und menschlichen aus Synapsen bestehenden Strukturen im Gehin sind nach \cite{haykin2007neural}:

\begin{enumerate}
    \item \glqq Das Akquirieren von Wissen des Netzwerks durch einen von der Umgebung\linebreak abhängigen Lernprozess\grqq{} (\cite{haykin2007neural})
    \item \glqq Die Stärke von Interneuronalen Verbindungen, bekannt als synaptische Gewichte, wird verwendet um akquirierte Informationen zu speichern\grqq{} (\cite{haykin2007neural})
\end{enumerate}

\cite{haykin2007neural} beschreibt Neuronale Netze dabei als Netzwerke aus Schichten, die wiederum aus einzelnen Neuronen bestehen. Diese Neuronen sind von Schicht zu Schicht miteinander verbunden. Solche Verbindungen ähneln wie von \cite{haykin2007neural} ursprünglich beschrieben Synapsen mit Gewichten, durch die das Netzwerk lernt, welche Verbindungen mehr und welche weniger \glqq gestärkt \grqq{} werden müssen, um ein richtiges Ergebnis zu erhalten. So eine Verbindung $i$ setzt sich in einem Neuronalen Netz also vereinfacht stets zusammen aus Gewicht $w$, dem Input-Signal des eingebenden Neurons $y$ und dem Bias $b$.

$$i=w*y-b$$

Ein Neuron besteht somit nach \cite{haykin2007neural} aus der Summe aller seiner einfließenden Verbindungen. Die einfachste Form eines Neuralen Netzes ist demnach ein \textit{Single-Layer Feedforward Network} mit nur einer Schicht, welches auch allgemein als Perzeptron bezeichnet wird. Fügt man eine Schicht zwischen dem Input- und Output-Layer hinzu, so bezeichnet man diese als \textit{hidden layer} (HL). Hidden Layer dienen nach \cite{haykin2007neural} dazu, den Input des Netzwerks vor der Ausgabe zu verarbeiten, wodurch das Netzwerk komplexere Aufgabenstellungen lösen kann. Solche Netzwerke benötigen laut \cite{haykin2007neural}, um nicht auf die Input-Output Beziehung eines gewöhnlichen Perzeptrons reduziert zu werden, sogenannte nicht-lineare Aktivierungsfunktionen. Eine häufig verwendete Aktivierungsfunktion ist hier laut \cite{haykin2007neural} die \textit{Sigmoid}-Aktivierungsfunktion, wobei die \textit{Rectified Linear Unit}-Aktivierungsfunktion besonders in den letzten Jahren an Beliebtheit gewann (\cite{lecun2015deep}), was auf ihre guten Ergebnisse (\cite{nair2010rectified}), sowie bessere Kompatibilität mit besonders Tiefen Neuronalen Netzen aufgrund von Effekten wie dem \textit{Vanishing Gradient} (\cite{hochreiter2001gradient}) zurückzuführen ist. Ein solches Neuron setzt sich also im Fall von $n$ einfließenden Verbindungen vereinfacht wie folgt zusammen:

$$i=\sigma(w_1y_1+w_2y_2+w_3y_3+...+w_na_n - b)$$

$\sigma$ steht dabei in diesem Fall für die \textit{Sigmoid}-Aktivierungsfunktion. Netzwerke mit mehr als zwei Schichten, also mindestens zwei HL und einem Output Layer, werden als Tiefe Neuronale Netze bezeichnet. Netzwerke lernen laut \cite{haykin2007neural} durch schrittweise Korrektur von Fehlern in den Gewichten des Netzwerks. Das geschieht mittels dem \textit{Backpropagation} (BP) Algorithmus. Das Netzwerk wird dabei einmal vorwärts mit statischen Gewichten und rückwärts mit Anpassung der Gewichte durchlaufen. Dabei wird am Ende des ersten Durchlaufes nach vorne der Fehlerwert für jedes Output-Neuron bestimmt. Die quadrierte Summe aller Fehler der Neuronen ergibt die \textit{Kostenfunktion} des Netzwerks. Anschließend wird ein \textit{Gradient} berechnet, der die Richtung und Intensität der Anpassung im Gewichts des Neurons angibt. Diese Anpassung wird als \textit{Gradientenabstieg} bezeichnet und hat als Ziel, die Kostenfunktion des Netzwerks zu minimieren. Der Gradient kann nun mit der Lernrate, die als Hyperparameter festgelegt werden kann und damit die Größe der getätigten Schritte Richtung Optimum kontrolliert, und dem Input-Signal des Neuronen multipliziert werden, um die vorzunehmende Korrektur des Gewichts zu erhalten. Eine solche Optimierung der Kostenfunktion kann so rekursiv rückwärts auf jede Schicht in dem Netzwerk angewandt werden, um sich schrittweise einem Optimum zu nähern (\cite{haykin2007neural}).

Tiefe Neuronale Netze sind unter anderem deshalb Schwerpunkt dieser Arbeit, da diese in der Forschung zu der Klassifikation von EMG Signalen bereits gute Ergebnisse erzielten. So wurden in der Vergangenheit bereits Convolutional Neural Networks in Verbindung mit EMG-Datensätzen trainiert und erzielten sowohl mit konventionell initialisierten Gewichten (\cite{Allard2019}, \cite{geng2016gesture}), als auch mit durch Techniken des \textit{Transferlernens} initialisierten Gewichten, also mit Gewichten, die bereits durch die selbe oder andere Architekturen vortrainiert wurden, präzise Klassifikationsgenauigkeiten (\cite{cote2017transfer}). Auch in dem in dieser Arbeit weiter beleuchteten Bereich der \textit{Recurrent Neural Networks} wurden in der Vergangenheit für die Klassifikation von EMG Signalen bereits durch \cite{simao2019emg}, \cite{bu2003emg} und \cite{tsuji2000pattern} gute Ergebnisse in der Klassifikation erzielt.